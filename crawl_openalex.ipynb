{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19aaf71",
   "metadata": {},
   "source": [
    "# Thi·∫øt l·∫≠p config v√† c·∫•u h√¨nh chung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a895e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyalex\n",
    "from pyalex import config\n",
    "from itertools import chain\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "pyalex.config.email = \"thuattruongminh@gmail.com\"\n",
    "\n",
    "config.max_retries = 3\n",
    "config.retry_backoff_factor = 0.1\n",
    "config.retry_http_codes = [429, 500, 503]\n",
    "\n",
    "OUTPUT_FILE = \"openalex_computer_science.json\"\n",
    "FIELD = \"Computer Science\"\n",
    "FIELD_ID = \"C41008148\"\n",
    "DATA_NEED = [\"id\",\"title\",\"publication_year\",\"type\",\"language\",\"doi\",\n",
    "             \"concepts\",\"authorships\",\"locations\",\"primary_location\",\"cited_by_count\",\n",
    "             \"primary_topic\",\"keywords\"]\n",
    "MAX_RESULTS = 50\n",
    "DELAY = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb9e633",
   "metadata": {},
   "source": [
    "# Crawling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b00c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl():\n",
    "    print(f\"Crawling OpenAlex for field: {FIELD}\")\n",
    "    works = pyalex.Works().filter(concepts = {\"id\":FIELD_ID}).select(DATA_NEED).paginate(method = \"page\",per_page = 100)\n",
    "    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True) if \"/\" in OUTPUT_FILE else None\n",
    "    count_result = 0\n",
    "    with open(OUTPUT_FILE, \"a\", encoding=\"utf-8\") as f_out:\n",
    "        for page in works:\n",
    "            for record in page:\n",
    "                print(\"Crawl record: \",record[\"id\"])\n",
    "                json_line = json.dumps(record,ensure_ascii = False)\n",
    "                f_out.write(json_line + \"\\n\")\n",
    "                count_result += 1\n",
    "                if (count_result >= MAX_RESULTS):\n",
    "                    break\n",
    "                if (count_result % 100 == 0):\n",
    "                    print(f\"Crawled {count_result} records ...\")\n",
    "                time.sleep(DELAY)\n",
    "    print(f\"Saved {count_result} records into {OUTPUT_FILE}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eee04c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling OpenAlex for field: Computer Science\n",
      "Crawl record:  https://openalex.org/W2582743722\n",
      "Crawl record:  https://openalex.org/W2194775991\n",
      "Crawl record:  https://openalex.org/W2107277218\n",
      "Crawl record:  https://openalex.org/W1979290264\n",
      "Crawl record:  https://openalex.org/W2144634347\n",
      "Crawl record:  https://openalex.org/W2911964244\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mcrawl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m, in \u001b[0;36mcrawl\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrawl record: \u001b[39m\u001b[38;5;124m\"\u001b[39m,record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#json_line = json.dumps(record,ensure_ascii = False)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#f_out.write(json_line + \"\\n\")\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mOUTPUT_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     13\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(record, f, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     14\u001b[0m count_result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67b24451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling OpenAlex for field: Computer Science\n",
      "--- Fetching page 1, 100 records ---\n",
      "‚úÖ Crawled 50 records...\n",
      "Reached MAX_RESULTS limit.\n",
      "\n",
      "üéâ Done! Saved 50 records into openalex_computer_science.json\n"
     ]
    }
   ],
   "source": [
    "import pyalex\n",
    "from pyalex import Works\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "def crawl():\n",
    "    print(f\"Crawling OpenAlex for field: {FIELD}\")\n",
    "\n",
    "    works = Works().filter(concepts={\"id\": FIELD_ID}).select(DATA_NEED).paginate(\n",
    "        method=\"page\", per_page=100\n",
    "    )\n",
    "\n",
    "    # t·∫°o th∆∞ m·ª•c n·∫øu c·∫ßn\n",
    "    if \"/\" in OUTPUT_FILE:\n",
    "        os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    count_result = 0\n",
    "\n",
    "    try:\n",
    "        for page_idx, page in enumerate(works, start=1):\n",
    "            print(f\"--- Fetching page {page_idx}, {len(page)} records ---\")\n",
    "\n",
    "            for record in page:\n",
    "                results.append(record)\n",
    "                count_result += 1\n",
    "\n",
    "                if count_result % 50 == 0:\n",
    "                    print(f\"‚úÖ Crawled {count_result} records...\")\n",
    "\n",
    "                if count_result >= MAX_RESULTS:\n",
    "                    print(\"Reached MAX_RESULTS limit.\")\n",
    "                    break\n",
    "\n",
    "                time.sleep(DELAY)  # tr√°nh b·ªã gi·ªõi h·∫°n t·ªëc ƒë·ªô (rate limit)\n",
    "\n",
    "            if count_result >= MAX_RESULTS:\n",
    "                break\n",
    "\n",
    "        # ===== Ghi to√†n b·ªô d·ªØ li·ªáu v√†o file JSON =====\n",
    "        with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f_out:\n",
    "            json.dump(results, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"\\nüéâ Done! Saved {count_result} records into {OUTPUT_FILE}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error occurred: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    crawl()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d77c0ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
